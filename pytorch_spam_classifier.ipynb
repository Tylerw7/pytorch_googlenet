{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08a2a63a-e4c6-419b-ac59-5399be0a861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad0425d-5eb9-4706-adab-9d3a02962f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./spam_ham_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb88872-fee2-494d-b1a8-3416310bedd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2ae620d-b484-4344-a250-ba3b9e4584bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2b60f86-0f66-455c-a63a-07774736c768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Subject: hpl nom for january 9 , 2001\\r\\n( see attached file : hplnol 09 . xls )\\r\\n- hplnol 09 . xls'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99682e95-2508-47ae-aaf5-d053596ab9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Subject: hpl nom for january 9 , 2001 ( see attached file : hplnol 09 . xls ) - hplnol 09 . xls'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.text = df.text.apply(lambda x: x.replace('\\r\\n', ' '))\n",
    "df1.text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4634f98-9b03-4b2c-afdd-21bf9bc8c5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5171"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df1.drop('label', axis=1)\n",
    "len(df2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b0f9de3-a711-47ec-a677-a862296add7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5171 5171\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X = df2.text\n",
    "y = df2.label_num\n",
    "print(len(X),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f0a8814-e364-490e-8e88-6bf1eaa57d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_vec = vectorizer.fit_transform(X)\n",
    "labels = df2.label_num.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e9c36bd-1285-450b-99c3-494e0d3f0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_vec,labels, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f94e75d7-d377-475c-9097-e987acfed441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1035,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d1fa5c8-0c10-425a-89c3-6950d7230fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "083095fd-7fbf-4189-9ca6-b8b900396990",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train.toarray(),dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.toarray(),dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train,dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test,dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5f739a3-8a82-4105-9e31-cc91531afaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4136, 1035)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_tensor), len(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d4cb277-6ba7-485a-85a8-ff95b4a15e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor,y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor,y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e2b8ab-f8e6-4412-85a1-7f481de7e92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c8ffbb2-362d-4f8c-8a02-13e9d27283f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 - Label: 1, Vector shape: torch.Size([5000])\n",
      "Sample 1 - Label: 1, Vector shape: torch.Size([5000])\n",
      "Sample 2 - Label: 0, Vector shape: torch.Size([5000])\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    X, y = train_dataset[i]\n",
    "    print(f\"Sample {i} - Label: {y}, Vector shape: {X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a89d31c1-195c-4f68-88a6-15c4309495a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce3dfcc-1538-42c4-b863-ecd5740aafdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36efb3db-a0f5-4206-afe0-ba33f003431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class  SpamClassifier(nn.Module):\n",
    "    def __init__(self, input_size, out_put, layers, drop_out=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        layerlist = []\n",
    "\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(input_size,i))\n",
    "            layerlist.append(nn.ReLU())\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(drop_out))\n",
    "            input_size = i\n",
    "\n",
    "        layerlist.append(nn.Linear(layers[-1], out_put))\n",
    "\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = self.layers(X)\n",
    "        return X\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d969fce4-e7cb-4fb8-8425-f894020ca1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpamClassifier(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=5000, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Dropout(p=0.5, inplace=False)\n",
       "    (12): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = SpamClassifier(5000, 2, [256,128,64], drop_out=0.5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a20a3ab7-ab59-4fa2-90a8-0cd1894744d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5ee4e06-1c47-40ee-a6c4-bab9ca82548e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1  loss: 0.07798538\n",
      "epoch: 1  loss: 0.06813315\n",
      "epoch: 1  loss: 0.09583057\n",
      "epoch: 1  loss: 0.08445978\n",
      "epoch: 1  loss: 0.10837626\n",
      "epoch: 1  loss: 0.08653607\n",
      "epoch: 1  loss: 0.06846983\n",
      "epoch: 1  loss: 0.07409866\n",
      "epoch: 1  loss: 0.05839927\n",
      "epoch: 1  loss: 0.13366187\n",
      "epoch: 1  loss: 0.05178288\n",
      "epoch: 1  loss: 0.07308362\n",
      "epoch: 1  loss: 0.09390484\n",
      "epoch: 1  loss: 0.03595007\n",
      "epoch: 1  loss: 0.07145340\n",
      "epoch: 1  loss: 0.06756314\n",
      "epoch: 1  loss: 0.09032404\n",
      "epoch: 1  loss: 0.02488624\n",
      "epoch: 1  loss: 0.08295932\n",
      "epoch: 1  loss: 0.10214652\n",
      "epoch: 1  loss: 0.05881514\n",
      "epoch: 1  loss: 0.02904821\n",
      "epoch: 1  loss: 0.06298947\n",
      "epoch: 1  loss: 0.03316285\n",
      "epoch: 1  loss: 0.09046593\n",
      "epoch: 1  loss: 0.10113331\n",
      "epoch: 1  loss: 0.04589811\n",
      "epoch: 1  loss: 0.04235240\n",
      "epoch: 1  loss: 0.03519171\n",
      "epoch: 1  loss: 0.07403626\n",
      "epoch: 1  loss: 0.04594018\n",
      "epoch: 1  loss: 0.02662151\n",
      "epoch: 1  loss: 0.02990822\n",
      "epoch: 1  loss: 0.05408601\n",
      "epoch: 1  loss: 0.03507973\n",
      "epoch: 1  loss: 0.04869901\n",
      "epoch: 1  loss: 0.06321923\n",
      "epoch: 1  loss: 0.15628402\n",
      "epoch: 1  loss: 0.05247109\n",
      "epoch: 1  loss: 0.07030680\n",
      "epoch: 1  loss: 0.03418914\n",
      "epoch: 1  loss: 0.04200914\n",
      "epoch: 1  loss: 0.01404689\n",
      "epoch: 1  loss: 0.05176055\n",
      "epoch: 1  loss: 0.01293198\n",
      "epoch: 1  loss: 0.05246459\n",
      "epoch: 1  loss: 0.02628031\n",
      "epoch: 1  loss: 0.07900470\n",
      "epoch: 1  loss: 0.13671099\n",
      "epoch: 1  loss: 0.01882553\n",
      "epoch: 1  loss: 0.08309053\n",
      "epoch: 1  loss: 0.13791221\n",
      "epoch: 1  loss: 0.01680542\n",
      "epoch: 1  loss: 0.03700201\n",
      "epoch: 1  loss: 0.02795538\n",
      "epoch: 1  loss: 0.03348542\n",
      "epoch: 1  loss: 0.01822827\n",
      "epoch: 1  loss: 0.04273673\n",
      "epoch: 1  loss: 0.01344936\n",
      "epoch: 1  loss: 0.02435688\n",
      "epoch: 1  loss: 0.08725815\n",
      "epoch: 1  loss: 0.05609452\n",
      "epoch: 1  loss: 0.01579382\n",
      "epoch: 1  loss: 0.03453926\n",
      "epoch: 1  loss: 0.03870595\n",
      "epoch: 3  loss: 0.01275274\n",
      "epoch: 3  loss: 0.04273225\n",
      "epoch: 3  loss: 0.02681591\n",
      "epoch: 3  loss: 0.00325012\n",
      "epoch: 3  loss: 0.01388101\n",
      "epoch: 3  loss: 0.00431086\n",
      "epoch: 3  loss: 0.00647166\n",
      "epoch: 3  loss: 0.01361161\n",
      "epoch: 3  loss: 0.00651820\n",
      "epoch: 3  loss: 0.00586638\n",
      "epoch: 3  loss: 0.00496680\n",
      "epoch: 3  loss: 0.01053775\n",
      "epoch: 3  loss: 0.01218435\n",
      "epoch: 3  loss: 0.01716245\n",
      "epoch: 3  loss: 0.03221226\n",
      "epoch: 3  loss: 0.08659802\n",
      "epoch: 3  loss: 0.01368461\n",
      "epoch: 3  loss: 0.00824123\n",
      "epoch: 3  loss: 0.01665779\n",
      "epoch: 3  loss: 0.01722942\n",
      "epoch: 3  loss: 0.00619893\n",
      "epoch: 3  loss: 0.00908807\n",
      "epoch: 3  loss: 0.00739972\n",
      "epoch: 3  loss: 0.02808166\n",
      "epoch: 3  loss: 0.00257915\n",
      "epoch: 3  loss: 0.00607376\n",
      "epoch: 3  loss: 0.00918125\n",
      "epoch: 3  loss: 0.00297035\n",
      "epoch: 3  loss: 0.00533570\n",
      "epoch: 3  loss: 0.00191293\n",
      "epoch: 3  loss: 0.00734820\n",
      "epoch: 3  loss: 0.01421342\n",
      "epoch: 3  loss: 0.00359333\n",
      "epoch: 3  loss: 0.00795491\n",
      "epoch: 3  loss: 0.09586606\n",
      "epoch: 3  loss: 0.00812528\n",
      "epoch: 3  loss: 0.00477190\n",
      "epoch: 3  loss: 0.00880466\n",
      "epoch: 3  loss: 0.03952428\n",
      "epoch: 3  loss: 0.00388066\n",
      "epoch: 3  loss: 0.00948799\n",
      "epoch: 3  loss: 0.07477177\n",
      "epoch: 3  loss: 0.00452018\n",
      "epoch: 3  loss: 0.00955779\n",
      "epoch: 3  loss: 0.00681695\n",
      "epoch: 3  loss: 0.00606702\n",
      "epoch: 3  loss: 0.04244943\n",
      "epoch: 3  loss: 0.09596858\n",
      "epoch: 3  loss: 0.00942607\n",
      "epoch: 3  loss: 0.00472607\n",
      "epoch: 3  loss: 0.00223810\n",
      "epoch: 3  loss: 0.00363345\n",
      "epoch: 3  loss: 0.00610143\n",
      "epoch: 3  loss: 0.00529874\n",
      "epoch: 3  loss: 0.00544103\n",
      "epoch: 3  loss: 0.01726773\n",
      "epoch: 3  loss: 0.00533498\n",
      "epoch: 3  loss: 0.09715177\n",
      "epoch: 3  loss: 0.01892069\n",
      "epoch: 3  loss: 0.00384126\n",
      "epoch: 3  loss: 0.02252189\n",
      "epoch: 3  loss: 0.01738901\n",
      "epoch: 3  loss: 0.00478105\n",
      "epoch: 3  loss: 0.00724144\n",
      "epoch: 3  loss: 0.01808836\n",
      "epoch: 5  loss: 0.00455773\n",
      "epoch: 5  loss: 0.00471503\n",
      "epoch: 5  loss: 0.00388280\n",
      "epoch: 5  loss: 0.00389386\n",
      "epoch: 5  loss: 0.00488504\n",
      "epoch: 5  loss: 0.00388018\n",
      "epoch: 5  loss: 0.00118024\n",
      "epoch: 5  loss: 0.00837652\n",
      "epoch: 5  loss: 0.00312955\n",
      "epoch: 5  loss: 0.00913934\n",
      "epoch: 5  loss: 0.00457523\n",
      "epoch: 5  loss: 0.00852829\n",
      "epoch: 5  loss: 0.00553078\n",
      "epoch: 5  loss: 0.00223029\n",
      "epoch: 5  loss: 0.00532165\n",
      "epoch: 5  loss: 0.00594116\n",
      "epoch: 5  loss: 0.00465141\n",
      "epoch: 5  loss: 0.00210055\n",
      "epoch: 5  loss: 0.00863033\n",
      "epoch: 5  loss: 0.00246567\n",
      "epoch: 5  loss: 0.00302792\n",
      "epoch: 5  loss: 0.00175852\n",
      "epoch: 5  loss: 0.00333746\n",
      "epoch: 5  loss: 0.00302493\n",
      "epoch: 5  loss: 0.00264460\n",
      "epoch: 5  loss: 0.00363067\n",
      "epoch: 5  loss: 0.00180852\n",
      "epoch: 5  loss: 0.00385801\n",
      "epoch: 5  loss: 0.00115674\n",
      "epoch: 5  loss: 0.00118901\n",
      "epoch: 5  loss: 0.01702933\n",
      "epoch: 5  loss: 0.00807416\n",
      "epoch: 5  loss: 0.00422408\n",
      "epoch: 5  loss: 0.02717146\n",
      "epoch: 5  loss: 0.00244198\n",
      "epoch: 5  loss: 0.00936110\n",
      "epoch: 5  loss: 0.00160296\n",
      "epoch: 5  loss: 0.01061173\n",
      "epoch: 5  loss: 0.01816844\n",
      "epoch: 5  loss: 0.04525758\n",
      "epoch: 5  loss: 0.00503908\n",
      "epoch: 5  loss: 0.00636919\n",
      "epoch: 5  loss: 0.00348377\n",
      "epoch: 5  loss: 0.00168308\n",
      "epoch: 5  loss: 0.00568638\n",
      "epoch: 5  loss: 0.01886859\n",
      "epoch: 5  loss: 0.00242510\n",
      "epoch: 5  loss: 0.00155853\n",
      "epoch: 5  loss: 0.00220316\n",
      "epoch: 5  loss: 0.05156135\n",
      "epoch: 5  loss: 0.00160499\n",
      "epoch: 5  loss: 0.00251006\n",
      "epoch: 5  loss: 0.00841793\n",
      "epoch: 5  loss: 0.00917601\n",
      "epoch: 5  loss: 0.00254109\n",
      "epoch: 5  loss: 0.00296476\n",
      "epoch: 5  loss: 0.03755628\n",
      "epoch: 5  loss: 0.00255256\n",
      "epoch: 5  loss: 0.02341054\n",
      "epoch: 5  loss: 0.01564211\n",
      "epoch: 5  loss: 0.00281317\n",
      "epoch: 5  loss: 0.00785451\n",
      "epoch: 5  loss: 0.00368475\n",
      "epoch: 5  loss: 0.00432278\n",
      "epoch: 5  loss: 0.13655017\n",
      "epoch: 7  loss: 0.00288321\n",
      "epoch: 7  loss: 0.13229576\n",
      "epoch: 7  loss: 0.06736453\n",
      "epoch: 7  loss: 0.01834216\n",
      "epoch: 7  loss: 0.00249399\n",
      "epoch: 7  loss: 0.00202120\n",
      "epoch: 7  loss: 0.00482769\n",
      "epoch: 7  loss: 0.02909559\n",
      "epoch: 7  loss: 0.00216085\n",
      "epoch: 7  loss: 0.03809400\n",
      "epoch: 7  loss: 0.00330984\n",
      "epoch: 7  loss: 0.01874297\n",
      "epoch: 7  loss: 0.00471434\n",
      "epoch: 7  loss: 0.00147138\n",
      "epoch: 7  loss: 0.01194130\n",
      "epoch: 7  loss: 0.00071104\n",
      "epoch: 7  loss: 0.00177637\n",
      "epoch: 7  loss: 0.00863724\n",
      "epoch: 7  loss: 0.00193480\n",
      "epoch: 7  loss: 0.00401071\n",
      "epoch: 7  loss: 0.00393488\n",
      "epoch: 7  loss: 0.01228855\n",
      "epoch: 7  loss: 0.13225169\n",
      "epoch: 7  loss: 0.00162636\n",
      "epoch: 7  loss: 0.00227609\n",
      "epoch: 7  loss: 0.00284081\n",
      "epoch: 7  loss: 0.00289825\n",
      "epoch: 7  loss: 0.00194901\n",
      "epoch: 7  loss: 0.00307998\n",
      "epoch: 7  loss: 0.00238247\n",
      "epoch: 7  loss: 0.00404291\n",
      "epoch: 7  loss: 0.00081909\n",
      "epoch: 7  loss: 0.00263899\n",
      "epoch: 7  loss: 0.00210039\n",
      "epoch: 7  loss: 0.00366359\n",
      "epoch: 7  loss: 0.00194597\n",
      "epoch: 7  loss: 0.05294149\n",
      "epoch: 7  loss: 0.00750057\n",
      "epoch: 7  loss: 0.00362586\n",
      "epoch: 7  loss: 0.00540863\n",
      "epoch: 7  loss: 0.00126080\n",
      "epoch: 7  loss: 0.00999832\n",
      "epoch: 7  loss: 0.04573566\n",
      "epoch: 7  loss: 0.01965013\n",
      "epoch: 7  loss: 0.00295493\n",
      "epoch: 7  loss: 0.00350185\n",
      "epoch: 7  loss: 0.00218561\n",
      "epoch: 7  loss: 0.00290071\n",
      "epoch: 7  loss: 0.00341380\n",
      "epoch: 7  loss: 0.00676682\n",
      "epoch: 7  loss: 0.00561065\n",
      "epoch: 7  loss: 0.00410408\n",
      "epoch: 7  loss: 0.00503133\n",
      "epoch: 7  loss: 0.00304735\n",
      "epoch: 7  loss: 0.00210724\n",
      "epoch: 7  loss: 0.00505016\n",
      "epoch: 7  loss: 0.00268316\n",
      "epoch: 7  loss: 0.00338855\n",
      "epoch: 7  loss: 0.04530487\n",
      "epoch: 7  loss: 0.00203963\n",
      "epoch: 7  loss: 0.00427472\n",
      "epoch: 7  loss: 0.00168644\n",
      "epoch: 7  loss: 0.00516483\n",
      "epoch: 7  loss: 0.02042225\n",
      "epoch: 7  loss: 0.00067057\n",
      "epoch: 9  loss: 0.04594551\n",
      "epoch: 9  loss: 0.00099227\n",
      "epoch: 9  loss: 0.00159106\n",
      "epoch: 9  loss: 0.00546633\n",
      "epoch: 9  loss: 0.00416066\n",
      "epoch: 9  loss: 0.00288106\n",
      "epoch: 9  loss: 0.00099963\n",
      "epoch: 9  loss: 0.00479466\n",
      "epoch: 9  loss: 0.00103649\n",
      "epoch: 9  loss: 0.00560427\n",
      "epoch: 9  loss: 0.01461531\n",
      "epoch: 9  loss: 0.00119101\n",
      "epoch: 9  loss: 0.00159330\n",
      "epoch: 9  loss: 0.00077474\n",
      "epoch: 9  loss: 0.00510944\n",
      "epoch: 9  loss: 0.10939351\n",
      "epoch: 9  loss: 0.00296684\n",
      "epoch: 9  loss: 0.00140972\n",
      "epoch: 9  loss: 0.00109794\n",
      "epoch: 9  loss: 0.22499172\n",
      "epoch: 9  loss: 0.00298801\n",
      "epoch: 9  loss: 0.00061737\n",
      "epoch: 9  loss: 0.00541313\n",
      "epoch: 9  loss: 0.00119385\n",
      "epoch: 9  loss: 0.01636309\n",
      "epoch: 9  loss: 0.00475238\n",
      "epoch: 9  loss: 0.00122257\n",
      "epoch: 9  loss: 0.00245226\n",
      "epoch: 9  loss: 0.00294988\n",
      "epoch: 9  loss: 0.00322671\n",
      "epoch: 9  loss: 0.00302721\n",
      "epoch: 9  loss: 0.04621691\n",
      "epoch: 9  loss: 0.00114893\n",
      "epoch: 9  loss: 0.00153222\n",
      "epoch: 9  loss: 0.00320056\n",
      "epoch: 9  loss: 0.00067500\n",
      "epoch: 9  loss: 0.00199038\n",
      "epoch: 9  loss: 0.04243372\n",
      "epoch: 9  loss: 0.00164965\n",
      "epoch: 9  loss: 0.02766738\n",
      "epoch: 9  loss: 0.00064573\n",
      "epoch: 9  loss: 0.00131652\n",
      "epoch: 9  loss: 0.00239833\n",
      "epoch: 9  loss: 0.00293054\n",
      "epoch: 9  loss: 0.00400227\n",
      "epoch: 9  loss: 0.01312130\n",
      "epoch: 9  loss: 0.00088876\n",
      "epoch: 9  loss: 0.01191987\n",
      "epoch: 9  loss: 0.02317864\n",
      "epoch: 9  loss: 0.00097985\n",
      "epoch: 9  loss: 0.00110662\n",
      "epoch: 9  loss: 0.00079468\n",
      "epoch: 9  loss: 0.00110821\n",
      "epoch: 9  loss: 0.00501911\n",
      "epoch: 9  loss: 0.00195374\n",
      "epoch: 9  loss: 0.01307950\n",
      "epoch: 9  loss: 0.00046439\n",
      "epoch: 9  loss: 0.00069091\n",
      "epoch: 9  loss: 0.00198396\n",
      "epoch: 9  loss: 0.00511624\n",
      "epoch: 9  loss: 0.01149440\n",
      "epoch: 9  loss: 0.00145950\n",
      "epoch: 9  loss: 0.00486941\n",
      "epoch: 9  loss: 0.01175260\n",
      "epoch: 9  loss: 0.00126453\n",
      "Total training time: 2.5672059059143066\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "for i  in range(epochs):\n",
    "    \n",
    "    for n,(X_train,y_train) in enumerate(train_loader):\n",
    "        y_pred = model(X_train)\n",
    "        loss = criterion(y_pred,y_train)\n",
    "\n",
    "        if i%2 == 1:\n",
    "            print(f'epoch: {i}  loss: {loss.item():10.8f}')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f'Total training time: {total_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29f16954-d279-4d63-985d-7323e05f770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader): \n",
    "    model.eval() \n",
    "    correct = 0 \n",
    "    counter = 0 \n",
    "    with torch.no_grad(): \n",
    "        for X_test,y_test in test_loader:\n",
    "            y_val = model(X_test) \n",
    "            _,pred = torch.max(y_val.data,1) \n",
    "            counter += y_test.size(0) \n",
    "            correct += (pred==y_test).sum().item() \n",
    "            \n",
    "    print(100*correct/counter)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed868f2a-b3d4-4024-a067-d263a26ff82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.26086956521739\n"
     ]
    }
   ],
   "source": [
    "test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88210f38-6eda-40da-90c6-5ce18a016810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST MODEL\n",
    "\n",
    "def predict(email):\n",
    "    model.eval()\n",
    "    X_new = vectorizer.transform(email)\n",
    "    X_new_tensor = torch.tensor(X_new.toarray(), dtype=torch.float32)  # shape [1, 5000]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_new_tensor)\n",
    "        predicted_class = torch.argmax(y_pred, dim=1).item()\n",
    "\n",
    "    label_map = {0: \"ham\", 1: \"spam\"}\n",
    "    print(f\"The model predicts: {label_map[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89bfae36-33f1-4c10-9d7d-abf78407e4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicts: spam\n"
     ]
    }
   ],
   "source": [
    "predict([\"Click promotion for discount!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7f39e3-2843-40d4-95da-31e7603d129a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
